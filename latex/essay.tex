\documentclass[a4paper]{article}

\def\npart{III Essay}

\def\ntitle{Walking Deeper on Dynamic Graphs}

\def\ndate{\today}

\input{header}

\let\SO\undefined
\usepackage{tkz-graph}
\usepackage{thm-restate}
\usepackage{algpseudocode}
\usepackage{algorithm}
\newcommand{\shadow}{\partial}
\renewcommand{\P}{\mathbb P}
\renewcommand{\E}{\mathbb E}
\newcommand{\D}{\mathcal D}
\renewcommand{\G}{\mathcal G}
\renewcommand{\V}{\mathcal V}
\newcommand{\rar}{\overrightarrow r}
\newcommand{\lar}{\overleftarrow r}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\algnewcommand{\LineComment}[1]{\State \(\triangleright\) #1}
\begin{document}

\input{titlepage}

\tableofcontents

\section{Introduction}
The motivation of this essay and the methods it presents comes from the desire to understand networks of people and the relationships between them.
From a mathematical perspective, the natural way to go about studying social networks is to let nodes of a graph G represent the people and edges their relationships. From this, we can induce some understanding of the neighbourhoods that a network consists of. This task of understanding the communities that exist in a social network is a complex one; even with a relatively small number of people it is not a task for which humans perform very well and the task rapidly becomes difficult as the size of the network increases.\\
Network embeddings are a useful way to characterise the complex structures that
can exist in these graphs. The idea behind them is to represent each member of a
network with a point in space, where the distance according to some metric
(often simply Euclidean) between any two points corresponds to the similarity of
the members in the network. These points in space are called vertex
representations. The difficulty with this approach is defining a suitable
similarity function $f(p1,p2)$ that gives a good understanding of the network
structure. This ambiguity of similarity has led to a diverse range of algorithms for calculating network embeddings.
\begin{figure}[h!]
  \centering
  \includegraphics[width = 1\textwidth]{src/DeepWalkOnKarateGraph.png}

  \caption{Two dimensional network embeddings calculated using
    DeepWalk on Zachary's Karate network\cite{zachary1977}. There is a strong
    correspondence between community structure in the original graph and
    in the embedding space. Vertex colours are representing a modularity-based
    clustering of the input graph. In practive, network embeddings have dimensions
    in the tens to low-hundreds and t-SNE is often used to visualise these embeddings in 2D
    space.\cite{maaten2008}}
\end{figure}\\
The problem of analysing social structures is made more difficult still by the
fact that such networks often change over time. As new connections are formed
and others die away, the network moves and over a long time period, it can
change significantly. Calculating the vertex representations for a large social
graph, where the size of the network is often in the millions or billions, takes
a lot of time. It is therefore computationally infeasible to recalculate these
representations at every time step and so a more intelligent approach to this
problem is required.\\
This essay looks at DeepWalk and how it can be modified for dealing with dynamic
graphs. DeepWalk is an algorithm that calculates vertex representations for
large social graphs by using techniques adapted from natural language processing. When proposed in 2014, the algorithm was a first of its kind and has since sparked a large amount of future research, with new algorithms improving upon it using similar methods. The core idea behind DeepWalk is to model random walks on a graph similar to sentences in a large corpus of text, this idea is explored further throughout the essay.


\subsection{Summary}
The section on DeepWalk explores the fundamental connection between DeepWalk and
matrix factorisation as presented in the paper by Qiu et al.\cite{qiu2018}. In
this section, we demonstrate the conditions under which DeepWalk is factorising
an appropriate matrix that stores some measure of similarity between
nodes in the graph. In the section ``Why DeepWalk sucks'' we look at some of the
criticism that followed the original DeepWalk paper and how these criticisms
were addressed by future authors, the section is indicative of the shortcomings
of DeepWalk but is by no means exhaustive.\\
After this, the section ``Dynamic DeepWalking'' focusses on applying a variant of the DeepWalk algorithm, proposed
by Sajjad et al. \cite{sajjad2019}, for dynamic graphs. This is especially
important in the context of social graphs, which usually contain temporal information
about user interactions. Learning social
representations for dynamic graphs can allow for a better understanding of how
communities move and change over time.\\
Finally, to exhibit Dynamic DeepWalking in practice, the final section of this
essay applies the Unbiased Update algorithm introduced by Sajjad et
al.\cite{sajjad2019} to data from users on the social network Gab to look at how
user interaction on the network varies with time. 

\subsection{Preliminary Notation}
I have endeavoured to use similar notation to the original DeepWalk paper\cite{deepwalk} to ease
cross-referencing. However given that a number of other papers are touched upon
throughout the essay, there are some pieces of notation that have been changed.
If reading through the essay systematically, the reader should not find
difficulty following the notation.

\begin{definition}[(Partially Labelled) Network Graph]
  Let $G = (V, E)$ be an undirected graph (representing a network). $V$ represents the
  members of the network, commonly referred to as the \textit{nodes} or \textit{vertices} and $E \subset V
  \times V$ represents their connections, usually referred to as
  \textit{edges}.\\
  Some of the nodes and edges have labels and $G_L = (V, E, X, Y)$ represents the
  partially labelled network. The node features are represented by $X \in \R^{|V| \times S}$ where $S$ is the size of
  the feature space for each attribute vector. The node labels are represented by $Y \in \R^{|V|
    \times|\mathcal{Y}|}$, where $\mathcal{Y}$ is the set of labels.
\end{definition}
Some of the nodes are labelled with $y \in \mathcal{Y}$ and the end task is to
predict the labels of the other nodes. This is called a \termit{relational
  classification problem}. The aim of the DeepWalk algorithm is to learn embeddings $W \in \R^{|V| \times d}$ where $d$ is a small number
of latent dimensions ($d \ll |V|$) such that each of the rows in $W$
corresponds to a $d$ dimensional embedding of a node in $V$.\\
To avoid confusion, it is important to distinguish that the goal of DeepWalk is
not to classify the nodes, but to generate useful embeddings. These embeddings
are then treated as additional features and are combined with the features $X$
to be inputted into a classification algorithm.
\section{DeepWalk}
This section gives an outline of the social representation learning algorithm
DeepWalk, first introduced in the seminal paper DeepWalk: Online Learning of
Social Representations by B. Perozzi et. al. \cite{deepwalk}. The method proposed in
this paper not only demonstrated performance improvements from previous methodologies but
also motivated an entirely different approach. At the time of the paper being
written, significant advancements were being made in natural language processing (NLP)
and the idea of word embeddings was becoming popular through an embedding
algorithm known as Word2Vec \cite{mikolov2013efficient,mikolov2013distributed}.
DeepWalk implements this algorithm but replaces the idea of the context of a word in
a sentence with the context of a node in a random walk on a graph. This is the
crucial concept of DeepWalk from which the remaining details of the algorithm naturally follow.\\
The original paper on DeepWalk is lacking in a mathematical foundation and so in
this section we will model the algorithm mathematically. It is suggested that the reader
is familiar with the concepts outlined in the paper by Perozzi et. al. prior to
reading this (more) mathematical exposition.
\begin{algorithm}
  \caption{DeepWalk}
  \begin{algorithmic}[1]
    \Require{network $G(V, E)$}
    \Statex window size $k$
    \Statex embedding size $d$
    \Statex walks per vertex $\gamma$
    \Statex walk length $l$
    \Ensure{matrix of vertex representations $W \in \R^{|V| \times d}$}
    \State Initialization: Sample $W$ from $\mathcal{U}^{|V| \times d}$
    \For{$i = 0$ to $\gamma$}
    \State $\mathcal{O} = \text{Shuffle}(V)$
    \For{\textbf{each} $v \in \mathcal{O}$}
    \State $\mathcal{W}_v =$ RandomWalk$(G, v, l)$
    \State Skipgram$(W, \mathcal{W}_v, k)$
    \EndFor
    \EndFor
  \end{algorithmic}
\end{algorithm}
\subsection{Introduction to DeepWalk}
To understand DeepWalk mathematically, we first need to understand what the SkipGram
model is doing, since this is the model underpinning DeepWalk. SkipGram was
prposed by Mikolev et al.\cite{mikolov2013efficient} as an efficient way to
learn word embeddings. The idea behind SkipGram is to learn embeddings which are good at
predicting nearby words in sentences. For a sentence $w_1, ... , w_N$, the
nearby words from $w_i$, known as context words, are defined as the set of words
within distance $k$, $\{w_{i-k}, w_{i-k+1}, \dots , w_{i+k}\} \setminus w_i$, where $k$ is the size of the window. SkipGram
minimises the following objective function
\[\mathcal{L} = - \sum_{c \in C(w)} \log{\P(c | w)}\]
where $\P(c | w)$ is modelled by a softmax function
\[\P(u|v) = \frac{\exp{(\vec{w} \cdot \vec{c}})}{\sum_{c \in \mathcal{F}}\exp{(\vec{w} \cdot
    \vec{c}})}\]
where $\mathcal{F}$ is the vocabulary and $\vec{w}$ represents the
embedding of the word $w$ and $\vec{c}$ the distributed representation of $c$ when it serves as a
context word.\\
*** Can I be clearer about what this distributed representation is? ***\\
Perrozi et al. took this model from NLP and applied it to graphs by observing
that nodes in the graph can be thought of as words in an antificial language.
Firstly, to find the context for each node, DeepWalk generates random walks
which are analagous to sentences in a language. The context nodes are the set of
nodes within a window of size $k$, from which input-context pairs $(v, c)$ are
constructed and added to a corpus $\D$, which is a multi-set. After these context nodes have been
found the same optimization function as in SkipGram is used to learn embeddings which maximise
the chance of predicting context nodes.\\
Algorithm 1 shows how DeepWalk is applied. $\gamma$ represents the number of
random walks that are started from each node and at the start of each pass the
nodes are shuffled so that they are traversed in a random order.\footnote{This
  helps to prevent the algorithm from staying in a local minima when stochastic
  gradient descent is applied since on each iteration, as the vertices
  are shuffled, the shape of the loss surface changes.} For each node
$v \in V$ a random walk $\mathcal{W}_v$ of length $l$ is generated and used to
update the network embeddings using the SkipGram algorithm applied to the random
walk.\\
From the perspective of machine learning, SkipGram trains a neural network to do
a ``fake'' task. It trains on this task, and then the corresponding weights
learned are used as embeddings. The task is as follows:\\
Given an input vertex $v$ somewhere in a random walk $\mathcal{W}$. Pick a
nearby vertex at random. The task of the neural network is to
predict the probability that each vertex in $V$ will be this randomly chosen
vertex. Therefore, verticies far away on the graph that correspond to unfamiliar
nodes are unlikely to co-occur on the same random walk and will be assigned a
low probability. Conversely, nearby and well connected vertices are likely to
co-occur on a random walk with input $v$ and thus will be assigned higher
probabilities. This allows us to train a network with weights that represent the
connectedness between nodes on the graph. The neural network is trained by
feeding it pairs of nodes $(v, c)$ where $v$ represents the input node and $c$
is a context node, which lies within distance $k$ of the vertex $v$.\\ 

To formalise this, each of the nodes $v \in V$ are represented by a one-hot
encoding vector $e_v \in \mathbb{R}^{|V|}$ allowing us to feed $e_v$ into the
neural network. When $e_v$ is fed into the network, a single linear hidden layer with
$d$ neurons is used, where $d$ is the desired dimension of the latent
representations, which is then passed to a softmax classifier for output. The
output of the network is a vector $o \in \mathbb{R}^{|V|}$ containing the estimated
probabilities that a randomly selected nearby word is that vocabulary word.

The idea behind having a linear hidden layer, which does not use an activation
function, is to use the resulting weight matrix $W \in \mathbb{R}^{|V| \times
  d}$ as the embedding vectors for the nodes in the graph. This is intuitive as
the hidden layer acts as a bottleneck that tries to represent as much
information as possible to distinguish the nodes, but is only allowed $d$
neurons to do so. Since $d \ll |V|$ there is a low risk of overfitting.
% This creates the neural network diagram for the SkipGram neural network
\begin{figure}[h!]
  \centering
\tikzset{%
  every neuron/.style={
    circle,
    draw,
    minimum size=0.6cm
  },
  neuron missing/.style={
    draw=none, 
    scale=3,
    text height=0.2cm,
    execute at begin node=\color{black}$\vdots$
  },
}

\begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]

\foreach \m/\l [count=\y] in {1}
  \node [every neuron/.try, neuron \m/.try] (input-\m) at (0,0) {};

\foreach \m [count=\y] in {1, missing,2}
  \node [every neuron/.try, neuron \m/.try ] (hidden-\m) at (2,2 - \y) {};

\foreach \m [count=\y] in {1,2,3,missing,4}
  \node [every neuron/.try, neuron \m/.try ] (output-\m) at (4,2.25-\y*0.75) {};

\foreach \l [count=\i] in {1}
  \draw [<-] (input-\i) -- ++(-1,0)
    node [above, midway] {$e_v \in \R^{|V|}$};

\foreach \l [count=\i] in {1,d}
  \node [above] at (hidden-\i.north) {$H_\l$};

\foreach \l [count=\i] in {1,2,3,|V|}
  \draw [->] (output-\i) -- ++(1,0)
    node [above, midway] {$o_{\l}$};

\foreach \i in {1}
  \foreach \j in {1,...,2}
    \draw[orange] [->] (input-\i) -- (hidden-\j);

\foreach \i in {1,...,2}
  \foreach \j in {1,2,3,...,4}
    \draw[orange] [->] (hidden-\i) -- (output-\j);

\node [align=center, above] at (0,2) {Input Vector};
\node [align=center, above] at (2,2) {Hidden Layer\\\textit{Linear}};
\node [align=center, above] at (4,2) {Output Layer\\\textit{Softmax}};
\end{tikzpicture}
\caption{The structure of the neural network that is trained to obtain
  the weight matrix $W$ used for the network embeddings in the SkipGram algorithm.}
\end{figure}
\\
The algorithm used in DeepWalk varies slightly from the SkipGram algorithm
discussed. Calculating the normalization factor in the Softmax layer requires a
computational complexity of $O(|V|)$, which is intractable since this is often
in the millions or billions. In the original DeepWalk paper this is
reduced by using Hierarchical Softmax to approximate the softmax probabilities,
requiring a complexity of only $O(log|V|)$. In particular, a Huffman coding is
used to reduce the access time of frequent elements in the tree, as suggested by
Mikolov et al. in the original Word2Vec
papers.\cite{mikolov2013efficient,mikolov2013distributed}\\
In later adaptations of DeepWalk, SkipGram with Negative Sampling (SGNS) is used instead of
Hierarchical Softmax. Negative Sampling updates only a sample of the output
vectors per iteration. In the remainder of this essay, when referring to DeepWalk, it will be
implicitly assumed that Negative Sampling is used as appose to Hierarchical
Softmax. This is because SGNS has been found to be more efficient
and therefore has been adopted by much of the further literature. This convention will also
serve us well when we look at applying DeepWalk to dynamic graphs since here
Negative Sampling is also applied.\\
*** Can give a summary of NS here, if so just summarise what is said in Blog
Post 2 on SkipGram ***\\
*** Has NS been shown, or just found empirically, to be more efficient then
Hierarchical Softmax? Check node2vec paper for information on this. ***\\
\subsection{SkipGram as matrix factorisation}
In this section we will exhibit a proof that SGNS is
equivalent to factorising a certain matrix $M$ into two smaller matricies $W$
and $C$ where the rows in $W$ correspond to the learned embedding of each vertex
in the graph. This result was first proved by Levy and
Goldberg\cite{levy&goldberg} in the context of word embeddings.\\
\subsubsection{Objective of SGNS}
Given an arbitrary input-context pair $(v,c)$ the objective is to determine if
the pair comes from the random-walk corpus $\mathcal{D}$.\\
Let $P(\D = 1 | v, c)$ denote the probability that $(v,c)$ comes from a random
walk on the graph and $P(\D = 0| v, c)$
the probability it does not. Then the distribution is modelled by a sigmoid
function
\[P(D = 1 | v, c) = \sigma(\vec{v} \cdot \vec{c}) = \frac{1}{1 + e^{-\vec{v} \cdot \vec{c}}}\]
where $\vec{v}$ and $\vec{c}$ are $d$-dimensional vectors to be learned. SGNS attempts to maximise $P(\mathcal{D} = 1 | v,c)$ for observed pairs $(v, c)$
whilst simultaneously maximising $P(\D = 0 | v, c)$ for randomly sampled
negative examples.\\
It assumes that randomly selecting a context $c$ for a given
node $v$ is likely to result in a ``negative sample'', an unobserved pair $(v,c)$. In the context of
social networks, this assumption is reasonable since social networks are almost
always sparse (The number of edges is usually $O(|V|)$). However in a different
context, if the network is dense, then this may be an unreasonable assumption.\\
According to this assumption, the objective function of SGNS for a single
observation $(v,c)$ is:
\[\phi(v, c) = \log{\sigma(\vec{v} \cdot \vec{c})} + b \cdot \E_{c_{N} \sim P_D}\log{\sigma(-\vec{v} \cdot \vec{c})}\]
where the minus sign comes from the fact that $1 - \sigma(x) = \sigma(-x)$, $b$
is the number of negative samples and $c_N$ is the sampled context node, drawn
according to $P_D (c) = \frac{\#(c)}{| \D |}$ which is known as the unigram
distribution.\\

*** The objective function and this bit generally needs more explanation, read
Mikolev et al. to get a better grasp. It is not clear here. ***
\begin{notation} $\#(v,c)$, $\#(v)$ and $\#(c)$ denote the number of times vertex-context pair
  $(v,c)$, vertex $v$ and context $c$ appear in the generated random-walk corpus
  $\mathcal{D}$ respectively.
\end{notation}
This objective function is trained using stochastic gradient descent with
updates after each  observed pair in the random-walk corpus $\D$. The resulting
global objective becomes
\begin{equation}
  \mathcal{L} = \sum_{v \in V} \sum_{c \in V} \phi(v, c)
\end{equation}
\subsubsection{Finding the similarity function learned by SkipGram}
If we let $W$ be the matrix with rows $v_i$ (The matrix $W$ is used to highlight
that it is the weight matrix in the neural network presented in [Figure XX]) and $C$ the matrix with columns
$c_i$ then SGNS can be interpreted as factorising a matrix $M = WC^T$. An entry in the matrix $M_{ij}$ corresponds to the dot product $\vec{v_i} \cdot
\vec{c_j}$. Therefore SGNS is factorising a matrix in which each row corresponds
to an input node $v_i \in |V|$ and each column to a context node $c_j \in |V|$ and the value of $M_{ij}$ expresses the
strength of association between the input-context pair $(v_i, c_j)$ using some similarity
function $s(v_i,c_j)$. What is the similarity function learned by SkipGram? 
\begin{theorem}[Levy, Goldberg (2014)]
  SkipGram with Negative Sampling (SGNS) is implicitly factorising a matrix $M =
  WC^T$ with
  \[M_{ij} = \log{\frac{\#(v_i,c_j)|\mathcal{D}|}{\#(v_i)\#(c_j)}} - \log{b}\]
  where $W, C \in \mathbb{R}^{|V| \times d}$, and $b$ is the number of negative samples.
\end{theorem}

\begin{proof}
  Firstly, for sufficiently large dimensionality $d$ (so as to allow for a perfect
  reconstruction of $M$), each of the products $v_i \cdot c_j$ can be assumed to
  take their values independently of the others.
  *** WHY. EXPLAIN THIS. Why not sufficiently large value of $|\D|$, why does $d$
  matter here? ***

  Due to this independence, the objective function $\mathcal{L}$ can be maximised with
  respect to each pair $v \cdot c$ individually.

  The expectation term can be written explicitly as
  \begin{align*}
    \E_{\tilde{c} \sim P_{\D}}[\log{\sigma(-\vec{v} \cdot \vec{\tilde{c}})}] &= \sum_{\tilde{c} \in V}{\frac{\#(\tilde{c})}{|\D|} \log{\sigma(-\vec{v} \cdot \vec{\tilde{c}})}}\\
                                                                             &= \frac{\#(c)}{|\D|} \log{\sigma(-\vec{v} \cdot \vec{c})} + \sum_{\tilde{c} \in V \setminus \{c\}}{\frac{\#(\tilde{c})}{|\D|} \log{\sigma(-\vec{v} \cdot \vec{\tilde{c}})}}
  \end{align*}
  and the objective function $\mathcal{L}$ can be expressed as
  \begin{equation*}
    \mathcal{L} =  \sum_{v \in V}\sum_{c \in V}\#(v, c)\log{\sigma(\vec{v} \cdot \vec{c})} + \sum_{v \in V}\#(v)\left(b \cdot \E_{\tilde{c} \sim P_{\D}}[\log{\sigma(-\vec{v} \cdot \vec{\tilde{c}})}] \right)
  \end{equation*}
  where the second term comes from the fact that $\#(v) = \sum_{c \in V}\#(v,c)$
  by definition. Combining these equations gives that the local objective for an input-context
  pair is
  \begin{equation*}
    \phi(v, c) = \#(v, c)\log{\sigma(\vec{v} \cdot \vec{c})} + b \cdot \#(v)\cdot \frac{\#(c)}{|\D|}\log{-\sigma(-\vec{v} \cdot \vec{c})} 
  \end{equation*}
  To simplify the notation let $x = \vec{v} \cdot \vec{c}$ and, since we are
  assuming each of the $\vec{v_i} \cdot \vec{c_j}$ to take their values
  independently, we take the partial derivatve with respect to $x$ and optimise
  the local objective:
  \[\frac{\partial{\phi}}{\partial{x}} = \#(v, c) \cdot \log{\sigma(-x)} - b \cdot
    \#(v) \cdot \frac{\#(c)}{|\D|} \cdot \sigma(x)\]
  Where the derivatives are since $\sigma'(x) = \sigma(-x)$. Setting
  the derivative to zero and multipying through by
  $\frac{-e^x}{\sigma(x)\sigma(-x)}$ gives:
  \[\frac{b \cdot \#(v) \cdot \#(c)}{|\D|}e^{2x} + \left( \frac{b \cdot \#(v)
        \cdot \#(c)}{|\D|} - \#(v, c) \right)e^x - \#(v, c) = 0\]
  This is a quadratic equation in $e^x$ with two solutions. The first solution,
  $e^x = -1$ is infeasable since $x \in \R$ and so the appropriate solution is
  \[e^x = \frac{\#(v,c) \cdot |\D|}{\#(v)\#(c)} \cdot \frac{1}{b}\]
  Substituting $x = \vec{v} \cdot \vec{c}$ back into the equation and taking
  logs gives
  \[M_{ij} = \vec{v} \cdot \vec{c} = log{\left( \frac{\#(v, c) \cdot |\D|}{\#(v) \cdot
          \#(c)} \right)} - \log{b}\]
\end{proof}
Most interestingly, the resulting expression for the similarity function $s$ is
the pointwise mutual information (PMI) shifted by a factor of $\log b$. PMI was
first introduced as a measure of association between words in 1990 by Church and Hanks
\cite{church1990} and became widely adopted for NLP tasks.\\
*** Would make sense to go into this more ***\\
There is an equivalent theorem for SkipGram with Softmax that was proved by Yang
et al.\cite{yangalternative2015} and was later used in their development of
text-associated DeepWalk (TADW)\cite{yang2015} which encorporates text features
of the verticies in a social graph.

\begin{theorem}[Yang et al. (2015)]
  SkipGram with Softmax is implicitly factorising the matrix $M = WC^T$ with
  \[M_{ij} = \log{\frac{\#(v_i,v_j)}{\#(v_i)}}\]
\end{theorem}
The proof of this follows very similarly to the previous theorem and will not be
shown here since we will only be concerned with SGNS.

\subsection{DeepWalk as matrix factorisation}
We continue to look at DeepWalk in the context of matrix factorisation. Much of the proceeding analysis was exhibited in a recent paper by Qiu et
al.\cite{qiu2018} published in 2018 building upon work by Yang et al.\cite{yang2015}
from 2015. The aim of the former paper was to lay the foundationds for, and
unify, the SkipGram based network embedding methods. First we give some preliminary definitions.
\begin{definition}[Adjacency Matrix (A)]
  The adjacency matrix $A \in \R^{|V| \times |V|}$ for a graph $G$ is the matrix with $A_{ij} = 1$ if $(v_i, v_j) \in E(G)$ and $A_{ij} = 0$ otherwise.
\end{definition}

\begin{definition}[Degree Matrix (D)]
  The degree matrix $D \in \R^{|V| \times |V|}$ for a graph $G$ is a diagonal
  matrix with $D_{ii} = d_i = degree(v_i)$ for $v_i \in V$ and $D_{ij} = 0$ otherwise.
\end{definition}

\begin{definition}[Transition Matrix (P)]
  The transition matrix $P \in \R^{|V| \times |V|}$ for a graph $G$ is the
  matrix $P = D^{-1}A$. It has entries $P_{ij} = \frac{1}{d_i}$ if $(v_i, v_j)
  \in E(G)$ and $P_{ij} = 0$ otherwise. It is the transition matrix
  corresponding to a simple random walk on the graph $G$. 
\end{definition}
In their paper, Qiu et al. gave a theoretical understanding of the DeepWalk
algorithm by proving the following theorem:
\begin{restatable}[DeepWalk as implicit matrix factorisation]{theorem}{MainDeepWalk}
  As $l \to \infty$, DeepWalk is equivalent to factorising
  \[\log{\left(\frac{2|E|}{k}\left( \sum_{r = 1}^k P^r  \right) D^{-1}
      \right)} - \log{b}\]
  where $b$ is the negative sampling rate.
\end{restatable}
The theorem assumes that the graph is undirected and that it is connected so
that $P$ is irreducible. It is also assumed that the graph is
non-bipartite to ensure that the random walk converges to it's invariant distribution. In the application to
social network graphs, this
assumption will almost certainly hold as the existence of an odd cycle is
expected (Social networks usually contain a large amount of triangles,
representing mutual friends or connections). It is possible however that the
graph is not connected, in this case a dummy node can be introduced which
contains edges to all nodes which will not affect the community structure,
provided the graph sub-communities are sufficiently dense.
What follows in the remainder of this section is a careful outline of the proof.\\
*** If want to include details on bipartite asssumption, see the folder for
DeepWalk for more information. ***\\
Firstly, $\pi_i = \frac{d_i}{2|E|}$ satisfies the detailed balance equations:
\[\pi_i P_{ij} = d_i\cdot \frac{1}{d_i} = d_j \cdot \frac{1}{d_j} = \pi_j P_{ji}\]
and $\sum_{v_i \in V} \pi_i = 1$.Thus $\pi$ defines a distribution which is
invariant for a simple random walk on the graph. Since the state space is
finite and by assumption, $P$ is irreducible, a random walk on $G$ defines an
irreducible Markov Chain $X$ with transition matrix $P$. Therefore $\pi$ is
unique by the following theorem
\begin{theorem}
  Consider an irreducible Markov chain. Then
  \begin{itemize}
  \item[(i)] There exists an invariant distribution if and only if some state is
    positive recurrent.
  \item[(ii)] If there is an invariant distribution $\pi$, then every state is
    positive recurrent, and
    \[\pi_i = \frac{1}{\mu_i}\]
    for $i \in S$, where $\mu_i$ is the mean recurrence time of $i$. In
    particular, $\pi$ is unique.
  \end{itemize}
\end{theorem}
This is a standard proof in any course on Markov Chains and so the proof is
omitted here. See Page 31 of \cite{markov_chains} for details of a proof. As
well as this, since $P$ is irreducible and thus positive recurrent since the
graph is finite, under the further assumption that a simple random walk on the
graph is aperiodic the distribution of the chain tends towards $\pi$ as
$l \to \infty$.\\
To proceed with the first lemma it is useful to partition the random-walk corpus as follows:

\begin{definition}
  For $r = 1, \dots, k$, we define the following
  \[\D_{\rar} = \{ (v, c) : (v, c) \in \D, v = v_j, c = v_{j+r}\}\]
  \[\D_{\lar} = \{ (v, c) : (v, c) \in \D, v = v_{j+r}, c = v_{j}\}\]
  *** Need to give a proper definition to clarify what I mean here ***
  Thus $\D_{\rar}$/$\D_{\lar}$ are sub-multisets of $\D$ such that the context
  $c$ is $r$ steps after or before the vertex $v$ in random walks respectively.
\end{definition}

As an extension of previous definitions, we let $\#(v, c)_{\rar}$ and $\#(v,
c)_{\lar}$ denote the number of times that an input-context pair $(v,c)$ appears
in $\D_{\rar}$ and $\D_{\lar}$ respectively. Then the following lemma holds
\begin{lemma}
  As $l \to \infty$, we have
  \[\frac{\#(v, c)_{\rar}}{|\D_{\rar}|} \overset{p}{\to} \pi_v(P^r)_{v,c} \  \text{and}
    \ \frac{\#(v, c)_{\lar}}{|\D_{\lar}|} \overset{p}{\to} \pi_v(P^r)_{v,c} \]
\end{lemma}
\begin{proof}
  ***
  A proof of this can be found in Paper 2 but the proof is not nice, perhaps I can
  come up with an original proof of this using convergence of the random walk to
  it's invariant distribution.

  Note that by reversibility the two statements should be provably equivalent and
  I have used detailed balance here to prove that the two limits given in Paper 2
  are the same.

  I will leave this to come back to for a nicer proof.
  ***


  *** Note that Ref 3 gives info about as the length of the RWs becomes long, the
  singleton distribution of vertices will tend to the invariant distribution,
  referencing Modern Graph Theory, Bollobas ***
\end{proof}
From this we can show that
\begin{lemma}
  As $l \to \infty$, we have
  \[\frac{\#(v, c)}{|\D|} \overset{p}{\to} \frac{1}{k} \sum_{r = 1}^k \pi_v
    (P^r)_{v,c}\]
\end{lemma}
\begin{proof}
  \begin{align*}
    \frac{\#(v, c)}{|\D|} &=  \frac{\sum_{r=1}^k (\#(v, c)_{\rar} + \#(v, c)_{\lar})}{\sum_{r=1}^k (|\D_{\rar}| + |\D_{\lar}|)} = \frac{1}{2k} \sum_{r=1}^k \left( \frac{\#(v, c)}{|\D_{\rar}|} + \frac{\#(v, c)}{|\D_{\lar}|} \right)\\
                          &\overset{p}{\to} \frac{1}{k}\sum_{r=1}^{k} \frac{d_v}{2|E|}(P^r)_{v, c}
  \end{align*}
  where the second equality uses the fact that $|\D_{\rar}| = |\D_{\lar}| =
  \frac{|\D|}{2k}$ and the convergence comes from applying [Theorem XX],
  together with the continuous mapping theorem.
\end{proof}
This gives everything we need to prove the main theorem of this section, that
allows us to understand the matrix that DeepWalk is implicitely factorising.
\MainDeepWalk*
\begin{proof}
  Firstly, by summing the result of [Theorem XX] we get
  \begin{align*}
    \frac{\#(v)}{|\D|} &= \sum_{c \in V}\#(v, c)\\
                       &\overset{p}{\to} \sum_{c \in V} \frac{1}{k}\sum_{r=1}^k \pi_v(P^r)_{v, c}\\
                       &\frac{\pi_v}{k}\sum_{r = 1}^k \sum_{c \in V}(P^r)_{v,c} = \frac{\pi_v}{k}\sum_{r = 1}^k 1 = \pi_v
  \end{align*}
  since $P^r$ is stochastic for any $r$.\\
  Similarly, using the fact that $\pi$ is in detailed balance with $P$, and thus
  the result of [Theorem XX] can be rewritten as
  \[\frac{\#(v, c)}{|\D|} \overset{p}{\to} \frac{1}{k} \sum_{r = 1}^k \pi_c
    (P^r)_{c,v}\]
  it can be shown that $\frac{\#(c)}{|\D|} \overset{p}{\to} \pi_c$.\\
  Using this and by applying the continuous mapping theorem
  \begin{align*}
    \frac{\#(v, c) \cdot |\D|}{\#(v) \cdot \#(c)} = \frac{\frac{\#(v,c)}{|\D|}}{\frac{\#(v)}{|\D|} \cdot \frac{\#(c)}{|\D|}} & \overset{p}{\to} \frac{\frac{1}{k}\sum_{r=1}^{k} \frac{d_v}{2|E|}(P^r)_{v, c}}{\frac{d_v}{2|E|} \cdot \frac{d_c}{2|E|}}\\
                                                                                                                             &=\frac{2|E|}{k}\sum_{r=1}^k (P^r)_{v,c} \frac{1}{d_c} = \frac{2|E|}{k}\left( \sum_{r=1}^k(P^rD^{-1})_{v,c} \right)
  \end{align*}
  where the last equality follows since $D$ is diagonal.\\
  From this, applying [Theorem XX] gives that as $l \to \infty$ DeepWalk is equivalent to
  factorising
  \[\log \left( \frac{2|E|}{k}\left( \sum_{r=1}^k P^r \right)D^{-1}\right) - \log{b}\]
\end{proof}
This proof gives a better understanding of what the DeepWalk algorithm is doing.
There are many other good questions to ask about DeepWalk, for example whether
the algorithm is gaurunteed to converge under stochastic gradient descent, but
these questions will not explored in this essay.

*** Here can talk about how long it takes to tend towards this. Important point, how
large does $l$ need to be for this to be meaningful? ***
\section{Deep Drawbacks}
Whilst the original DeepWalk paper made a huge impact on the future development
of social representation learning on graphs, the algorithm itself has a number
of drawbacks that have been pointed out in subsequent papers. In this short
section, I will detail some of the issues and criticism of the implementation of DeepWalk.\\

Firstly, as has briefly been mentioned, in the original paper Hierarchical
Softmax was used to estimate the probabilities in the softmax layer of SkipGram.
This is important, since to calculate the partition function (denominator of the
softmax probability) would normally have complexity $O(|V|)$. Using Hierarchical
softmax however, the nodes are asssigned to the leaves of a binary tree. This
reduces the computational complexity to $O(\log{|V|})$.\\

Negative Sampling on the other hand is developed ...

*** Talk about Node2Vec and improvements to DeepWalk etc. Talk about various
shortcomings, just look at papers that came afterwards that shred DeepWalk.
Point to the algorithms that improved it.

Plan: Pick 2 or 3 algorithms, state what they improved, link to the papers.
***

*** node2vec ***

\subsection{Capturing Structural Similarity}
Another drawback of both DeepWalk and node2vec is that both of these algorithms
do well at capturing neighbourhouds in the graph, but they do not perform well
at capturing structural similarities amongst nodes. Applying DeepWalk to two nodes
that have a similar structural role in the graph but are in far away locations
will result in embeddings that are distant from eachother. An alternative
approach that performs significantly better at this task was suggested by
Ribeiro et al. in their paper on struc2vec\cite{}. Unlike DeepWalk, struc2vec does not
take distance between nodes into account and instead builds a context graph
whhere nodes are close together if they are structurally similar and then
SkipGram is applied in a simmilar mannner to DeepWalk, but this time on the
context graph instead of the original graph.\\
The approach of struc2vec is clearly to recognise a different kind of network
structure to the one DeepWalk was created to recognise. struc2vec is more
applicable to classification tasks where the labels depend heavily on the
structural role of the nodes. As an example, struc2vec would be more suitable
for the task of finding social group leaders within a large network
graph. In such a task it is not the communities that are important to identify,
but the roles people play within their communities. For this reason, it is
important to identify the suitability of a relational classification problem to
the application of DeepWalk.
\section{Dynamic DeepWalking}
In this section we transition away from the static implementation of DeepWalk
towards network embeddings for Dynamic datasets. In particular, the focus of the
section is to introduce an adaptation of DeepWalk to dynamic datasets as
proposed in the paper published by Sajjad et al.\cite{sajjad2019} in early
2019.\\
As stated in the motivation for the paper, most of the recently developed
representation learning methods can only be applied to static graphs while many
real-world graphs are constantly changing over time. Therefore, to apply these
methods the graph must be reanalysed at regular snapshots in time. This is very
inneficient. Sajjad et al. proposed a modified version of the DeepWalk
algorithm that is better suited to dynamic graphs and utilises the fact that the
graph structure is unlikely to change significantly to develop a much more
efficient way of analyzing social representation on dynamic graphs.
The computational complexity of the algorithm depends on the graph density and
number of edges added per epoch, however in the case of social networks these
are both low and thus the algorithm is well suited to this application.\\
Previous algorithms to be used on dynamic graphs have not used what
was learned about the graph in previous snapshots to efficiently calculate the
node representations in the next snapshot of time. The problem of doing so can
be split into two main tasks:

\begin{enumerate}
\item Generate a random walks corpus for a new snapshot of the graph based on
  a corpus from an older snapshot. In particular,
  we seek to find an efficent update algorithm that generates a set of random
  walks on the new snapshot from random walks on the old one, that is
  statistically indistinguishable from generating a set of random walks from
  scratch on the new snapshot of the graph.
  
\item  Update the vertex representations incrementally so that they do not need
  to be generated from scratch every time step.
  
\end{enumerate}
In what follows both of these tasks are explored. Firstly it is necessary to introduce notation appropriate for dynamic graphs.
\begin{definition}
A dynamic network graph is a series of network graphs $\G^t = \{\V^t,
  \mathcal{E}^t\}$ with $\V^t = \{v_1^t, \dots, v_{n(t)}^t\}$ and $\mathcal{E}^t = \{e_1^t, \dots,
  e_{m(t)}^t\}$, with $t$ a discrete series of times.
\end{definition}
A dynamic network graph is a series of updates to network graphs that consist of
adding/removing vertices and/or edges to the graph.
\begin{definition}[Deleted and added vertex sets]
  The sets of vertices and edges of the graph that are deleted from time $t$
  to $t+1$ are denoted by $D_{\V}^{t+1}$ and $D_{\mathcal{E}}^{t+1}$ respectively. The
  sets of added vertices and edges are denoted $A_{\V}^{t+1}$ and
  $A_{\mathcal{E}}^{t+1}$.\\
  The sets of all vertices contained in the added and deleted edges are denoted
  $\V(A_{\V}^{t+1})$ and $\V(D_{\mathcal{E}}^{t+1})$ respectively.
\end{definition}
Then to analyse the effect of changes on the random walks we define the
following terms:
\begin{itemize}
  \item \textit{Affected vertices}: All vertices that are in an added or removed
    edge which have not been deleted.
    \[\V_{\text{affected}}^{t+1} = \V(A_{\mathcal{E}}^{t+1}) \cup
      \V(D_{\mathcal{E}}^{t+1}) \setminus D_{\V}^{t+1}\]
    \item \textit{Affected walks}: All random walks i the corpus of random walks
      $W^t$ that contain at least one affected vertex.
    \end{itemize}
Importantly all unaffected walks in the corpus $W^t$ remain valid random walks
on the graph $\G_{t+1}$
\subsection{Updating the Random Walk Corpus}
As a preliminary solution to the problem of generating new random walks for the random
walk corpus an algorithm called Na誰ve Update Algorithm 2 is introduced. This
algorithm generates random walks of length $l$ for each of the affected vertices. Once this is complete, it updates the random walks $W^t$ by
replacing the old walks with the corresponding re-generated walks and adds the
random walks initiated from new vertices.\\
\begin{algorithm}[!h]
  \caption{Na誰ve Update}
  \begin{algorithmic}[1]

    \Procedure{Na誰veUpdate}{$\G^{t+1}, W^t, \V^1_{\text{affected}}, r, l$}
    \LineComment{Initialise r new walks from each of the affected vertices in $\V^1_{\text{affected}}$}
    \State $W$ \leftarrow initWalks($\V^1_{\text{affected}}, r$)
    \LineComment *** WHAT DOES THIS ACTUALLY DO? ***
    \State $W^{t+1}$ \leftarrow randomwalk($W, l \G^{t+1}$)
    \LineComment{Replace the old walks and add new ones}
    \State $W^{t+1}$ \leftarrow update($W^t, W^{t+1}$)
    \State \textbf{return} $W^{t+1}$
    \EndProcedure

  \end{algorithmic}
\end{algorithm}
However, Sajjad et al. show by way of example that the Na誰ve update algorithm has
biased empirical transition probabilities and that the resulting corpus of
random walks is not statistically indistinguishable from generating a new random
walk corpus at time $t+1$. To solve this problem a more sophisticated algorithm
must be introduced.
\subsubsection{Unbiased Update}

\begin{algorithm}[!h]
  \caption{Unbiased Update}
  \begin{algorithmic}[1]

    \Procedure{UnbiasedUpdate}{$\G^{t+1}, W^t, \V^1_{\text{affected}}, r, l$}
    \LineComment Partition the affected vertices into new and existing ones
    \State $\V_n$ \leftarrow newVertices($\V_{\text{affected}}^1$)
    \State $V_e$ \leftarrow existingVertices($\V_{\text{affected}}^1$)
    \LineComment Filter the existing random walk corpus to get only the walks
    that contain affected vertices (in $\V_e$)
    \State $W_{\text{affected}}$ \leftarrow filter($W^t, \V_e$)
    \LineComment Trim the affected walks to the first affected vertex
    \State $W_e$ \leftarrow trim($W_{\text{affected}}, \V_e$)
    \LineComment \leftarrow Initialise r walks from each of the new vertices in $\V_n$
    \State $W_n$ \leftarrow initWalks($\V_n, r$)
    \LineComment Take the union of the new walks to create the updated corpus
    \State $W$ \leftarrow $W_e \cup W_n$
    \State $W^{t+1}$ \leftarrow randomwalk($W, l, \G^{t+1}$)
    \State $W^{t+1}$ \leftarrow update($W^t, W^{t+1}$)
    \State \textbf{return} $W^{t+1}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
*** In the procedures I need to be clear about what initWalks and randomwalk are
doing ***\\
The motivation behind the unbiased update algorithm is the following: Consider a
random walk that has arrived at a vertex $v$ at any point along the walk, if
this vertex is not in the set $\V^{t+1}_{\text{affected}}$ then there is no
change to it's neighbours and thus the choice for the next vertex in the random
walk remains the same. However if $v \in \V^{t+1}_{\text{affected}}$ then the
neighbours of the vertex have changed which makes the random walk biased from
this vertex onwards since it evolves with incorrect transition probabilities. Therefore only the affected walks need to be updated to retain a statistically
satisfactory set of random walks at time $t+1$.\\

The Unbiased Update algorithm updates only those walks that contain vertices in
$\V^{t+1}_{\text{affected}}$ and does so by re-sampling the affected walks from
the first affected vertex in the walk. Searching for these affected vertices is computationally expensive so another algorithm,
Fast Update, is also suggested that generates the affected walks from the
begginning instead of trimming them. Whilst computationally more efficient, this
generates a biased random walk corpus. This is because by applying the Fast Update routine, we have
effectively generated random walks on the graph $\G^{t+1}$ and then regenerated
all walks that hit an affected vertex, results in a corpus that is biased towards walks
that do not visit the affected vertices.\\
In practice, when implementing the Unbiased Update algorithm the random seed
that is used to generate each of the walks can be stored and then used to
regenerate the random walks up to their first affected vertex by reusing the
seed. Therefore the Unbiased Update algorithm can be implemented with the same
complexity as the Fast Update algorithm.\\
*** Can I give a proof that the Unbiased Update algorithm does indeed generate
an unbiased corpus? They have given an explanation but it is not very
mathematical. ***\\
*** Can include the complexity analysis if need be but it is not particularly
informative ***

\subsection{Updating the Vertex Representations Efficiently}
Once the updated random walk corpus $W^{t+1}$ has been calculated, the vertex
representations must be updated. In the DeepWalk algorithm, SkipGram is used to
optimize the objective function $\mathcal{L}$ using SGNS.
The algorithm starts by initialising the vertex representations randomly and
uses stochastic gradient descent to optimize the objective function over the
input-context pairs in $\D_{t+1}$.\\
However, initialising the representations randomly in the dynamic case is
inefficient since between each epoch the optimal vertex representations are
similar. It is therefore much more efficient to initialise the vertex
representations at time $t+1$ as the corresponding representations at time $t$
with any new vertices being randomly initiated, before performing stochastic gradient
descent to minimize the SGNS objective function over the new random walks corpus
$W^{t+1}$. The idea behind this is similar to using pretrained weights in a transfer
learning problem instead of initialising weights randomly and results in
stochastic gradient descent converging at a much faster rate.\\
A potential downside of this is that if the objective function is not convex and
stochastic gradient descent gets stuck in a local minima whilst training then it
is more likely to stay there.\\
\section{Discussion of an application}
The aim of this section is to bring the theory discussed on Dynamic DeepWalking
into practice.
\section{Conclusion}
See the esssay descriptors. It is required to have a conclusion and suggested to
reccomend further areas of research!

\bibliography{references}
\bibliographystyle{ieeetr}



\printindex
\end{document}